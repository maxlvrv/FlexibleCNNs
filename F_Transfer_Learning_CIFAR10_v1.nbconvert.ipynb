{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "Date: 21 Dec 2019\n",
    "\n",
    "Python version:      3.7\n",
    "Tensorboard version: 1.14.0\n",
    "PyTorch version:     1.2.0\n",
    "\n",
    "@author: Maksim Lavrov\n",
    "\n",
    "Transfer learning on CIFAR10 dataset\n",
    "    â€¢ With a flexible layer implemented instead of the last convolutional layer\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    #transforms.Lambda(torgb) # Transform grayscale to RGB\n",
    "    ])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.CIFAR10('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "#create a dataset subset to reduce training time\n",
    "\n",
    "sampler_train = list(range(0, len(trainset), 5000))\n",
    "sampler_test = list(range(0, len(testset), 5000))\n",
    "trainset_samp = torch.utils.data.Subset(trainset, sampler_train)\n",
    "testset_samp = torch.utils.data.Subset(testset, sampler_test)\n",
    "\n",
    "#set size of batch and learning rate\n",
    "batch_size=4\n",
    "lr=0.001\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "\n",
    "class FlexiLayer(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1,\n",
    "                 bias=True, padding_mode='zeros'):\n",
    "        kernel_size = kernel_size\n",
    "        stride = stride\n",
    "        padding = padding\n",
    "        dilation = dilation\n",
    "        super(FlexiLayer, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation,\n",
    "            groups, bias, padding_mode)\n",
    "        \n",
    "        \n",
    "        self.threshold1 = nn.parameter.Parameter(torch.randn((4, 9, 8, 8)), requires_grad=True)\n",
    "        self.memorized = self.threshold1.clone()\n",
    "        self.memorized_1loop = []\n",
    "        self.memorized_1pixel = []\n",
    "        self.thresh_max = []\n",
    "        self.thresh_min = []\n",
    "        self.thresh_mean = []\n",
    "            \n",
    "    def forward(self, t):\n",
    "        \n",
    "        t_1 = F.relu(F.conv2d(t, self.weight)) # get convolution result\n",
    "        t_2 = F.avg_pool2d(t, kernel_size=5, stride=1) # get avg result with the same kernel size\n",
    "        t_2 = torch.cat((t_2, t_2, t_2), 1)\n",
    "        m = nn.Sigmoid()\n",
    "        print(t_2.shape)\n",
    "        print(self.threshold1.shape)\n",
    "        condmax = torch.sub(t_2, self.threshold1)\n",
    "        condconv = torch.sub(t_2, self.threshold1)\n",
    "        t_2 = m(condmax*50)*t_2 # \n",
    "        print('cond', condconv.shape)\n",
    "        print('t_1', t_1.shape)\n",
    "        t_1 = m(condconv*(-50))*t_1 # \n",
    "        t = torch.add(t_2, t_1)\n",
    "        #t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Building\n",
    "#Feature Extraction\n",
    "net = models.resnet18(pretrained=True)\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = net.fc.in_features\n",
    "net.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 120),\n",
    "    #Reshape(4,3,12,12),\n",
    "    #FlexiLayer(in_channels=3, out_channels=9, kernel_size=5),\n",
    "    #nn.Linear(in_features= 3 * 56 * 56, out_features=120),\n",
    "    nn.Linear(in_features=120, out_features=60),\n",
    "    nn.Linear(in_features=60, out_features=10)\n",
    ")\n",
    "#net.fc.weight.requires_grad = True\n",
    "#net.fc.bias.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.0.weight tensor([[ 0.0307, -0.0167, -0.0409,  ...,  0.0399, -0.0322,  0.0184],\n",
      "        [-0.0338,  0.0321, -0.0047,  ..., -0.0241, -0.0194,  0.0076],\n",
      "        [ 0.0306,  0.0022,  0.0387,  ...,  0.0348, -0.0010, -0.0372],\n",
      "        ...,\n",
      "        [-0.0103,  0.0039, -0.0159,  ..., -0.0340,  0.0049,  0.0179],\n",
      "        [-0.0323, -0.0180,  0.0340,  ..., -0.0038, -0.0231,  0.0183],\n",
      "        [ 0.0128,  0.0085, -0.0207,  ..., -0.0129,  0.0312,  0.0309]])\n",
      "fc.0.bias tensor([ 0.0005, -0.0232, -0.0103,  0.0324, -0.0351,  0.0007,  0.0219, -0.0174,\n",
      "         0.0080, -0.0348,  0.0169,  0.0415,  0.0217,  0.0103, -0.0186, -0.0226,\n",
      "         0.0009, -0.0425, -0.0398,  0.0055,  0.0436, -0.0341,  0.0120,  0.0359,\n",
      "         0.0432,  0.0313,  0.0305,  0.0239,  0.0439, -0.0269,  0.0202, -0.0073,\n",
      "        -0.0215,  0.0041,  0.0420, -0.0002, -0.0072, -0.0051, -0.0411, -0.0117,\n",
      "        -0.0280,  0.0184, -0.0277,  0.0086,  0.0379, -0.0028,  0.0062, -0.0298,\n",
      "        -0.0438, -0.0266, -0.0080,  0.0009, -0.0047, -0.0118,  0.0439, -0.0257,\n",
      "        -0.0214, -0.0019, -0.0256, -0.0085,  0.0070,  0.0045,  0.0315,  0.0280,\n",
      "        -0.0189, -0.0226, -0.0007,  0.0254,  0.0034, -0.0229,  0.0135,  0.0137,\n",
      "         0.0264,  0.0112, -0.0425, -0.0181, -0.0153,  0.0397, -0.0342,  0.0260,\n",
      "        -0.0066,  0.0356,  0.0028, -0.0112,  0.0092, -0.0201, -0.0111, -0.0096,\n",
      "         0.0348, -0.0244, -0.0126, -0.0381,  0.0220, -0.0186, -0.0376, -0.0057,\n",
      "        -0.0319,  0.0179,  0.0393, -0.0384,  0.0078, -0.0109,  0.0145,  0.0188,\n",
      "         0.0416,  0.0163, -0.0160, -0.0034,  0.0323,  0.0126, -0.0379, -0.0382,\n",
      "         0.0320,  0.0015, -0.0100, -0.0135, -0.0388,  0.0045, -0.0108, -0.0177])\n",
      "fc.1.weight tensor([[ 0.0567, -0.0168,  0.0483,  ...,  0.0398, -0.0613,  0.0308],\n",
      "        [-0.0874, -0.0523,  0.0798,  ...,  0.0262, -0.0410,  0.0577],\n",
      "        [ 0.0600,  0.0865,  0.0123,  ...,  0.0451, -0.0394, -0.0639],\n",
      "        ...,\n",
      "        [-0.0646, -0.0799,  0.0893,  ...,  0.0331, -0.0720, -0.0507],\n",
      "        [-0.0238, -0.0382,  0.0210,  ..., -0.0727,  0.0269,  0.0635],\n",
      "        [ 0.0251,  0.0574, -0.0822,  ..., -0.0376,  0.0825,  0.0831]])\n",
      "fc.1.bias tensor([ 0.0598,  0.0485,  0.0606, -0.0839, -0.0252, -0.0155, -0.0402,  0.0750,\n",
      "        -0.0681,  0.0042, -0.0848, -0.0228, -0.0700, -0.0283, -0.0067, -0.0023,\n",
      "        -0.0702,  0.0389, -0.0738,  0.0687,  0.0584,  0.0111, -0.0742, -0.0749,\n",
      "         0.0335,  0.0099, -0.0209,  0.0858, -0.0237,  0.0293, -0.0332, -0.0335,\n",
      "         0.0048, -0.0580, -0.0131,  0.0611,  0.0346, -0.0234,  0.0295, -0.0767,\n",
      "         0.0789, -0.0350, -0.0629,  0.0316,  0.0553, -0.0865,  0.0056, -0.0153,\n",
      "        -0.0595,  0.0885,  0.0534, -0.0773, -0.0023, -0.0185, -0.0708, -0.0313,\n",
      "         0.0381,  0.0164,  0.0254, -0.0349])\n",
      "fc.2.weight tensor([[ 0.0600, -0.0393,  0.0631,  0.0876,  0.0866, -0.0237, -0.0715,  0.0447,\n",
      "          0.0012, -0.1185, -0.0062, -0.1021, -0.0377,  0.1034, -0.0919,  0.0522,\n",
      "          0.0314, -0.1176,  0.1181,  0.0669, -0.0629, -0.0922, -0.0413,  0.0242,\n",
      "         -0.1166, -0.0429, -0.0603, -0.1174,  0.0074,  0.0165,  0.0879, -0.0992,\n",
      "         -0.1101, -0.0790, -0.0577, -0.0254,  0.0524, -0.0298, -0.1165, -0.0052,\n",
      "          0.0371, -0.0861,  0.0790, -0.0534,  0.0267, -0.0465,  0.0992, -0.0514,\n",
      "         -0.0016, -0.0112, -0.0567,  0.0048, -0.0652,  0.0837,  0.0623, -0.0401,\n",
      "         -0.0365,  0.0545,  0.1139, -0.0664],\n",
      "        [-0.0866, -0.0654, -0.1283, -0.0505,  0.0025, -0.0324,  0.0561,  0.0778,\n",
      "         -0.0785,  0.0533, -0.1204,  0.0689,  0.0861,  0.0086,  0.0204, -0.0997,\n",
      "          0.1027,  0.1150, -0.0800, -0.0442, -0.0133, -0.0926, -0.0409,  0.0436,\n",
      "          0.0235, -0.0987,  0.0005,  0.1067,  0.0719,  0.0948, -0.0646, -0.1172,\n",
      "         -0.0372, -0.0048,  0.0325,  0.0043,  0.0079, -0.0532, -0.0314, -0.0428,\n",
      "          0.0294,  0.0539, -0.0066,  0.0407,  0.1130, -0.0580,  0.0606, -0.1173,\n",
      "         -0.0721, -0.0557,  0.0561,  0.1181,  0.0600,  0.0040, -0.1090,  0.0695,\n",
      "          0.0253,  0.0267,  0.0670,  0.0973],\n",
      "        [-0.0835,  0.1166,  0.0443, -0.0573,  0.0608, -0.1010, -0.0457,  0.0450,\n",
      "          0.0276,  0.0241,  0.0550, -0.1091,  0.1183, -0.0627,  0.0463,  0.0300,\n",
      "          0.0174, -0.1118,  0.0125,  0.0010, -0.0681, -0.1107,  0.0443, -0.0331,\n",
      "          0.0184,  0.1100, -0.0173,  0.0177, -0.1150,  0.0949,  0.1217,  0.0158,\n",
      "          0.0876, -0.0231, -0.0494, -0.1113, -0.0614,  0.0880,  0.0443, -0.0118,\n",
      "         -0.0432,  0.1277, -0.0203, -0.1290,  0.1232,  0.0835, -0.0234, -0.0945,\n",
      "          0.1009,  0.0712,  0.0502, -0.0357,  0.0516, -0.1064, -0.1054,  0.1195,\n",
      "         -0.0410, -0.0194,  0.0567,  0.0149],\n",
      "        [-0.0316, -0.0934,  0.0026,  0.1068,  0.0459,  0.0655, -0.0856, -0.0905,\n",
      "         -0.0627, -0.0030,  0.0124, -0.1288,  0.0329,  0.0303,  0.0023, -0.0104,\n",
      "          0.0540, -0.1072, -0.0867,  0.0949, -0.0146,  0.1288, -0.1270, -0.0843,\n",
      "          0.0759, -0.0152,  0.0927,  0.0522,  0.0868, -0.0487, -0.0262,  0.0554,\n",
      "         -0.1266, -0.0872,  0.0283, -0.0527,  0.0494,  0.0225,  0.1057, -0.0725,\n",
      "         -0.0169,  0.0337,  0.0865,  0.0276, -0.0767,  0.0357,  0.0408,  0.1240,\n",
      "         -0.0304,  0.0662,  0.0037, -0.0915, -0.0609,  0.1013, -0.0228, -0.0802,\n",
      "         -0.1070, -0.0388, -0.1024, -0.1142],\n",
      "        [-0.0317,  0.0292,  0.0512,  0.0292, -0.1047,  0.0343,  0.0393,  0.0466,\n",
      "         -0.0527, -0.0845, -0.0032, -0.0297, -0.0476,  0.0444,  0.0502,  0.0559,\n",
      "         -0.0757, -0.0391,  0.0137, -0.1281, -0.0052,  0.0561, -0.0510,  0.0556,\n",
      "         -0.1123,  0.0810,  0.0279, -0.0571,  0.0927,  0.1024,  0.0509, -0.1007,\n",
      "          0.1000,  0.1070, -0.0865, -0.0603,  0.1088,  0.0270,  0.0118,  0.0455,\n",
      "          0.0434, -0.0240, -0.0332,  0.0136,  0.0316, -0.1227,  0.0953, -0.0546,\n",
      "          0.0671, -0.0005, -0.1190, -0.1189, -0.0407, -0.1014,  0.0667,  0.0307,\n",
      "          0.0149,  0.0069,  0.0263, -0.0033],\n",
      "        [-0.0572, -0.1159, -0.1201, -0.1168, -0.0193,  0.0070,  0.0172,  0.1056,\n",
      "          0.0240,  0.0101,  0.0577, -0.0373,  0.1091, -0.1113,  0.0591, -0.0344,\n",
      "         -0.0172, -0.0249,  0.0265,  0.0253, -0.1078, -0.0365,  0.0107, -0.0513,\n",
      "         -0.0600, -0.0385, -0.0319,  0.0805,  0.0358, -0.0211,  0.1148,  0.1025,\n",
      "         -0.1059, -0.0487, -0.0751, -0.0795,  0.0690,  0.0188, -0.0281,  0.0259,\n",
      "          0.1206, -0.1135,  0.0878, -0.0551, -0.0114, -0.0637,  0.0391, -0.0735,\n",
      "          0.0826, -0.1124,  0.1007, -0.0422,  0.1220,  0.1263, -0.1005,  0.0296,\n",
      "          0.0746, -0.1224, -0.0332,  0.0181],\n",
      "        [ 0.1264,  0.0176,  0.1201,  0.0323,  0.0511,  0.1273, -0.0914,  0.0759,\n",
      "          0.0355,  0.0210,  0.0063,  0.0408, -0.0706, -0.0358, -0.0771,  0.0911,\n",
      "          0.0377,  0.0043,  0.0370, -0.0262, -0.0300,  0.1101,  0.1115, -0.1109,\n",
      "          0.0252, -0.0073, -0.0017, -0.0511, -0.1195, -0.0367, -0.0166, -0.0942,\n",
      "          0.0713,  0.0891, -0.0325,  0.0645,  0.1121, -0.1132, -0.1191, -0.0501,\n",
      "          0.0066, -0.0462,  0.0542, -0.0442, -0.0041,  0.0211,  0.0233, -0.0229,\n",
      "          0.0266,  0.0157, -0.0052, -0.0772, -0.0485,  0.0056, -0.0512,  0.0759,\n",
      "          0.0267, -0.0341,  0.0152, -0.1273],\n",
      "        [-0.1145,  0.1041, -0.0300,  0.0475, -0.0205,  0.0573,  0.0837,  0.0435,\n",
      "          0.1239,  0.0696, -0.1122, -0.0809,  0.1041, -0.0842,  0.0652,  0.0295,\n",
      "         -0.0535, -0.0724, -0.0348, -0.0123, -0.0185,  0.1283, -0.0296, -0.0246,\n",
      "         -0.0121, -0.1081, -0.0502,  0.1259,  0.0208,  0.0730, -0.0719,  0.0831,\n",
      "          0.0673,  0.0637, -0.0513, -0.0649,  0.0526, -0.0216, -0.0295, -0.1006,\n",
      "          0.0131,  0.0646, -0.0641, -0.0032,  0.0318,  0.0743,  0.0434,  0.1110,\n",
      "          0.0941, -0.0361,  0.0379, -0.0066,  0.0686, -0.0281,  0.1045, -0.0173,\n",
      "          0.0548, -0.0958,  0.0490,  0.1204],\n",
      "        [ 0.0710, -0.0372,  0.0347,  0.0767, -0.0501,  0.0310, -0.0472, -0.0710,\n",
      "         -0.0421, -0.1265,  0.0216, -0.0666, -0.0445, -0.0829,  0.1098,  0.1045,\n",
      "         -0.0986,  0.0870, -0.0405, -0.0763,  0.0893, -0.0379,  0.0782,  0.0810,\n",
      "          0.1127, -0.0634,  0.1240, -0.0354,  0.0841, -0.0711, -0.0558, -0.0552,\n",
      "          0.0622,  0.0993,  0.0726,  0.0483,  0.0743,  0.0954, -0.1150, -0.1231,\n",
      "          0.0189,  0.0280,  0.0567, -0.0285,  0.0756,  0.1162, -0.1173, -0.0936,\n",
      "         -0.0805, -0.1153, -0.0756,  0.0110, -0.0148,  0.0886, -0.0045,  0.0801,\n",
      "         -0.0123,  0.0704,  0.1283, -0.0489],\n",
      "        [ 0.0206, -0.0273,  0.0756,  0.0818,  0.0154,  0.0258,  0.0520, -0.0612,\n",
      "          0.0344,  0.0925, -0.1153,  0.1093,  0.0105, -0.0234, -0.0343,  0.0047,\n",
      "         -0.0920, -0.0028, -0.0082,  0.0884,  0.1003, -0.1266,  0.0428, -0.1231,\n",
      "          0.0816, -0.0822,  0.1174, -0.0729,  0.0764,  0.0287,  0.1223, -0.0825,\n",
      "          0.0217, -0.0943,  0.0148, -0.0053,  0.0727, -0.0841, -0.0939, -0.0141,\n",
      "         -0.0938,  0.1272,  0.0872, -0.0242,  0.1063, -0.0946,  0.0795, -0.1123,\n",
      "          0.0093,  0.1090,  0.0087, -0.0006, -0.0653, -0.1130,  0.0663,  0.0428,\n",
      "         -0.0705, -0.0903, -0.0304,  0.0345]])\n",
      "fc.2.bias tensor([ 0.1163, -0.0015,  0.0961,  0.0247, -0.1101, -0.1074,  0.0077,  0.0843,\n",
      "         0.0334,  0.0143])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_ftrs = net.fc.in_features\n",
    "#net.fc = nn.Sequential(FlexiLayer(in_channels=1, out_channels=256, kernel_size=5),\n",
    "#                      nn.Linear(256, n_classes))\n",
    "# Add on classifier\n",
    "#net.classifier[6] = nn.Sequential(\n",
    " #                     FlexiLayer(in_channels=3, out_channels=6, kernel_size=5),\n",
    "  #                    nn.Linear(256, n_classes))\n",
    "\n",
    "#num_ftrs = net.fc.in_features\n",
    "#net.fc = nn.Linear(num_ftrs, n_classes) # 10 classes in the dataset\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 62361.094607800245\n",
      "epoch: 1 loss: 55696.136185228825\n",
      "epoch: 2 loss: 54434.94817149639\n",
      "epoch: 3 loss: 54116.29214271903\n",
      "epoch: 4 loss: 53998.34625171125\n",
      "epoch: 5 loss: 53730.587011791766\n",
      "epoch: 6 loss: 53298.87064033002\n",
      "epoch: 7 loss: 53311.091692097485\n",
      "epoch: 8 loss: 53350.631316021085\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(9):  # loop over the dataset multiple times\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        preds = net(inputs) # Pass batch\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "            \n",
    "    print(\"epoch:\", epoch, \"loss:\", total_loss)\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training dataset is  0.64042\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on the training dataset is ', total_correct / len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test dataset is: 62.820000 %\n"
     ]
    }
   ],
   "source": [
    "#evaluate model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy on the test dataset is: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model \n",
    "path = \"./models/ResNet_base_20202203.pt\" \n",
    "torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15:21 start 15:25 finish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
