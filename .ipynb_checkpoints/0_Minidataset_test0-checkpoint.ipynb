{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/dummy/test/cell'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7a1a1e61e0fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/dummy/test/cell'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Warning! Files detected in test data directory!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Moving files back to training data directory...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/dummy/test/cell'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Date: 20 Dec 2019\n",
    "\n",
    "Python version:      3.7\n",
    "Tensorboard version: 1.14.0\n",
    "PyTorch version:     1.2.0\n",
    "\n",
    "@author: Maksim Lavrov\n",
    "\n",
    "• Training test whether the threshold is changing\n",
    "    • Create a small dataset, get outputs\n",
    "    \n",
    "\t• Confirm proper training\n",
    "\t• Save after a single training loop\n",
    "    To see whether the learning is \"sticky\" - save \n",
    "    the threshold layer after a single training loop \n",
    "    and see if it is the same as with the full loop\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Precheck on directory structure\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "if os.listdir('data/dummy/test/cell'):\n",
    "    print (\"Warning! Files detected in test data directory!\")\n",
    "    print (\"Moving files back to training data directory...\")\n",
    "\n",
    "    for f in os.listdir('data/dummy/test/cell'):\n",
    "        shutil.move('data/dummy/test/cell/'+f,'data/dummy/train/cell/'+f)\n",
    "\n",
    "    for f in os.listdir('data/dummy/test/nocell'):\n",
    "        shutil.move('data/dummy/test/nocell/'+f,'data/dummy/train/nocell/'+f)\n",
    "        \n",
    "        \n",
    "print (\"Splitting all training data into 70% training and 30% test data directories...\")\n",
    "\n",
    "cell_data = os.listdir('data/dummy/train/cell')\n",
    "nocell_data = os.listdir('data/dummy/train/nocell')\n",
    "\n",
    "test_cell_data = random.sample(cell_data, int(0.3*len(cell_data)))\n",
    "test_nocell_data = random.sample(nocell_data, int(0.3*len(nocell_data)))\n",
    "\n",
    "for f in test_cell_data:\n",
    "    shutil.move('data/dummy/train/cell/'+f,'data/dummy/test/cell/'+f)\n",
    "\n",
    "for f in test_nocell_data:\n",
    "    shutil.move('data/dummy/train/nocell/'+f,'data/dummy/test/nocell/'+f)\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='data/dummy/train',\n",
    "                                           transform=transform)\n",
    "testset = torchvision.datasets.ImageFolder(root='data/dummy/test',\n",
    "                                           transform=transform)\n",
    "\n",
    "#set size of batch and learning rate\n",
    "batch_size=4\n",
    "lr=0.001\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexiLayer(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1,\n",
    "                 bias=True, padding_mode='zeros'):\n",
    "        kernel_size = kernel_size\n",
    "        stride = stride\n",
    "        padding = padding\n",
    "        dilation = dilation\n",
    "        super(FlexiLayer, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation,\n",
    "            groups, bias, padding_mode)\n",
    "        \n",
    "        self.threshold1 = nn.parameter.Parameter(torch.randn((4, 6, 24, 24)), requires_grad=True)\n",
    "        self.memorized = self.threshold1.clone()\n",
    "        self.memorized_1loop = []\n",
    "            \n",
    "    def forward(self, t):\n",
    "        \n",
    "        t_1 = F.relu(F.conv2d(t, self.weight)) # get convolution result\n",
    "        t_2 = F.max_pool2d(t, kernel_size=5, stride=1) # get max result with the same kernel size\n",
    "        m = nn.Sigmoid()\n",
    "        condmax = torch.sub(t_2, self.threshold1)\n",
    "        condconv = torch.sub(t_2, self.threshold1)\n",
    "        t_2 = m(condmax*50)*t_2 # \n",
    "        t_1 = m(condconv*(-50))*t_1 # \n",
    "        t = torch.add(t_2, t_1)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flex1 = FlexiLayer(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=2)\n",
    "\n",
    "    def forward(self, t):\n",
    "        \n",
    "        # (2) Flexible layer\n",
    "        t = self.flex1(t)\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (4) hidden linear layer\n",
    "        t = F.relu(self.fc1(t.reshape(-1, 12 * 4 * 4)))\n",
    "        \n",
    "        # (5) hidden linear layer\n",
    "        t = F.relu(self.fc2(t))\n",
    "        \n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t\n",
    "    \n",
    "    #where function\n",
    "    def where(self, cond, x_1, x_2):\n",
    "        return (cond * x_1) + ((1-cond) * x_2)\n",
    "\n",
    "net = Net()\n",
    "memorized = net.flex1.memorized\n",
    "imgplot = plt.imshow(net.flex1.threshold1.detach().numpy()[1,1,:] - memorized.detach().numpy()[1,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "#writer.add_image('four_fake_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        preds = net(inputs) # Pass batch\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        if i == 1:\n",
    "            net.flex1.memorized_1loop = net.flex1.threshold1\n",
    "\n",
    "            \n",
    "    print(\"epoch:\", epoch, \"loss:\", total_loss)\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_correct / len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(net.flex1.threshold1.detach().numpy()[1,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(net.flex1.threshold1.detach().numpy()[1,1,:] - memorized.detach().numpy()[1,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Although what if it changes every time after a single small training loop - how do I check for that?\n",
    "\n",
    "imgplot = plt.imshow(net.flex1.threshold1.detach().numpy()[1,1,:] - net.flex1.memorized_1loop.detach().numpy()[1,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
